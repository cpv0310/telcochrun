{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66074c4d-7327-4b7e-ba2e-5558ab34d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cdsw\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from churnexplainer import ExplainedModel, CategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45011e27-39ab-4c91-8376-829e7ab9d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()\n",
    "df.replace({\"SeniorCitizen\": {1: \"Yes\", 0: \"No\"}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef0011b-4de2-4378-a7af-66dfab3ea93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8058399696624953\n",
      "test 0.7912400455062572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.89      0.86      1300\n",
      "         Yes       0.62      0.51      0.56       458\n",
      "\n",
      "    accuracy                           0.79      1758\n",
      "   macro avg       0.73      0.70      0.71      1758\n",
      "weighted avg       0.78      0.79      0.78      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelcol = \"Churn\"\n",
    "\n",
    "df = (df\n",
    "      .replace(r\"^\\s$\", np.nan, regex=True).dropna().reset_index()\n",
    "      # drop unnecessary and personally identifying information\n",
    "      .drop(columns=['customerID'])\n",
    "     )\n",
    "try:\n",
    "    # when loading from external data source, this column has str dtype\n",
    "    df.replace({\"SeniorCitizen\": {\"1\": \"Yes\", \"0\": \"No\"}}, inplace=True)\n",
    "except:\n",
    "    # when loading from local data source, this column has int dtype \n",
    "    df.replace({\"SeniorCitizen\": {1: \"Yes\", 0: \"No\"}}, inplace=True)\n",
    "    \n",
    "df['TotalCharges'] = df['TotalCharges'].astype('float')\n",
    "df.index.name='id'\n",
    "\n",
    "\n",
    "# separate target variable column from feature columns\n",
    "datadf, labels = df.drop(labelcol, axis=1), df[labelcol]\n",
    "\n",
    "# recast all columns that are \"object\" dtypes to Categorical\n",
    "for colname, dtype in zip(datadf.columns, datadf.dtypes):\n",
    "  if dtype == \"object\":\n",
    "    datadf[colname] = pd.Categorical(datadf[colname])\n",
    "\n",
    "  \n",
    "# Prepare data for Sklearn model and create train/test split\n",
    "ce = CategoricalEncoder()\n",
    "X = ce.fit_transform(datadf)\n",
    "y = labels.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "ct = ColumnTransformer(\n",
    "    [(\"ohe\", OneHotEncoder(), list(ce.cat_columns_ix_.values()))],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Experiments options\n",
    "# If you are running this as an experiment, pass the cv, solver and max_iter values\n",
    "# as arguments in that order. e.g. `5 lbfgs 100`.\n",
    "if len(sys.argv) == 4:\n",
    "    try:\n",
    "        cv = int(sys.argv[1])\n",
    "        solver = str(sys.argv[2])\n",
    "        max_iter = int(sys.argv[3])\n",
    "    except:\n",
    "        sys.exit(\"Invalid Arguments passed to Experiment\")\n",
    "else:\n",
    "    cv = 5\n",
    "    solver = \"lbfgs\"  # one of newton-cg, lbfgs, liblinear, sag, saga\n",
    "    max_iter = 100\n",
    "\n",
    "# Instantiate the model\n",
    "clf = LogisticRegressionCV(cv=cv, solver=solver, max_iter=max_iter)\n",
    "pipe = Pipeline([(\"ct\", ct), (\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "\n",
    "# Train the model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Capture train and test set scores\n",
    "train_score = pipe.score(X_train, y_train)\n",
    "test_score = pipe.score(X_test, y_test)\n",
    "print(\"train\", train_score)\n",
    "print(\"test\", test_score)\n",
    "print(classification_report(y_test, pipe.predict(X_test)))\n",
    "datadf[labels.name + \" probability\"] = pipe.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "# Create LIME Explainer\n",
    "feature_names = list(ce.columns_)\n",
    "categorical_features = list(ce.cat_columns_ix_.values())\n",
    "categorical_names = {i: ce.classes_[c] for c, i in ce.cat_columns_ix_.items()}\n",
    "class_names = [\"No \" + labels.name, labels.name]\n",
    "explainer = LimeTabularExplainer(\n",
    "    ce.transform(datadf),\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    categorical_features=categorical_features,\n",
    "    categorical_names=categorical_names,\n",
    ")\n",
    "\n",
    "\n",
    "# Create and save the combined Logistic Regression and LIME Explained Model.\n",
    "explainedmodel = ExplainedModel(\n",
    "    data=datadf,\n",
    "    labels=labels,\n",
    "    categoricalencoder=ce,\n",
    "    pipeline=pipe,\n",
    "    explainer=explainer,\n",
    ")\n",
    "explainedmodel.save(model_name='telco_linear')\n",
    "\n",
    "\n",
    "# If running as as experiment, this will track the metrics and add the model trained in this\n",
    "# training run to the experiment history.\n",
    "cdsw.track_metric(\"train_score\", round(train_score, 2))\n",
    "cdsw.track_metric(\"test_score\", round(test_score, 2))\n",
    "#cdsw.track_metric(\"model_path\", explainedmodel.model_path)\n",
    "#cdsw.track_file(explainedmodel.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651b55b-41f9-4a40-b22d-f92261f9d336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41511a-eca8-414f-b140-54bf2d9cb754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6871c1-2634-412e-8f56-7921b05b3a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a65c7d-1389-4d85-af83-3a9817745a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190faa2-830d-4154-ac9b-24bb05681f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
